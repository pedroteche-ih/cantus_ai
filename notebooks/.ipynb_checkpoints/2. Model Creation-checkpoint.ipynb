{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:51:44.942006Z",
     "iopub.status.busy": "2024-05-28T00:51:44.941602Z",
     "iopub.status.idle": "2024-05-28T00:51:51.076677Z",
     "shell.execute_reply": "2024-05-28T00:51:51.075958Z",
     "shell.execute_reply.started": "2024-05-28T00:51:44.941986Z"
    },
    "id": "J5VUMSA34aq7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 00:51:46.505164: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-28 00:51:46.505217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-28 00:51:46.506408: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-28 00:51:46.513386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 00:51:49.058361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from midiutil import MIDIFile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:52:19.984478Z",
     "iopub.status.busy": "2024-05-28T00:52:19.983560Z",
     "iopub.status.idle": "2024-05-28T00:52:19.989821Z",
     "shell.execute_reply": "2024-05-28T00:52:19.988980Z",
     "shell.execute_reply.started": "2024-05-28T00:52:19.984457Z"
    },
    "id": "kVW2ouKw1r1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def note_to_midi(note, octave):\n",
    "    # MIDI note numbers for the notes in octave 0\n",
    "    note_map = {\n",
    "        'c': 0, 'c#': 1, 'd': 2, 'd#': 3, 'e': 4, 'f': 5, 'f#': 6,\n",
    "        'g': 7, 'g#': 8, 'a': 9, 'a#': 10, 'b': 11\n",
    "    }\n",
    "\n",
    "    # Convert note to lowercase to handle both upper and lower case inputs\n",
    "    note = note.lower()\n",
    "\n",
    "    # Calculate the MIDI number\n",
    "    midi_number = (octave + 1) * 12 + note_map[note]\n",
    "\n",
    "    return midi_number\n",
    "\n",
    "def melody_to_midi(melody, rhythm_pattern, velocity_pattern, filename):\n",
    "    midi = MIDIFile(1)\n",
    "    midi.addTempo(0, 0, 120)\n",
    "\n",
    "    for i, note in enumerate(melody):\n",
    "        pitch_class = note[:-1]\n",
    "        octave = note[-1]\n",
    "        pitch = note_to_midi(pitch_class.lower(), int(octave))\n",
    "        duration = rhythm_pattern[i % len(rhythm_pattern)]\n",
    "        velocity = velocity_pattern[i % len(velocity_pattern)]\n",
    "        midi.addNote(0, 0, pitch, i, duration, velocity)  # Add note with duration of 1\n",
    "\n",
    "    with open(filename, 'wb') as output_file:\n",
    "        midi.writeFile(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:52:21.252440Z",
     "iopub.status.busy": "2024-05-28T00:52:21.252033Z",
     "iopub.status.idle": "2024-05-28T00:52:21.255721Z",
     "shell.execute_reply": "2024-05-28T00:52:21.254956Z",
     "shell.execute_reply.started": "2024-05-28T00:52:21.252419Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/jovyan/workspace/cantus_ai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:52:22.523197Z",
     "iopub.status.busy": "2024-05-28T00:52:22.522631Z",
     "iopub.status.idle": "2024-05-28T00:52:27.857777Z",
     "shell.execute_reply": "2024-05-28T00:52:27.857155Z",
     "shell.execute_reply.started": "2024-05-28T00:52:22.523177Z"
    },
    "id": "w_vDc2kk7bIO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_dorian = pd.read_csv('output/antiphon_melodies.csv')\n",
    "tb_dorian = tb_dorian[tb_dorian['mode'].isin([str(x) for x in range(1, 9)])].dropna()\n",
    "unique_ids = tb_dorian.groupby('id')['notes'].apply(list).reset_index().drop_duplicates(subset = 'notes')['id'].tolist()\n",
    "tb_dorian = tb_dorian[tb_dorian['id'].isin(unique_ids)]\n",
    "test_set = np.random.choice(unique_ids, 100, replace = False)\n",
    "train_data = tb_dorian[~tb_dorian['id'].isin(test_set)]\n",
    "test_data = tb_dorian[tb_dorian['id'].isin(test_set)]\n",
    "melodies = train_data.groupby('id')['notes'].apply(list).tolist()\n",
    "modes = train_data.groupby('id')['mode'].first().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T01:39:22.160307Z",
     "iopub.status.busy": "2024-05-28T01:39:22.159756Z",
     "iopub.status.idle": "2024-05-28T01:39:28.776711Z",
     "shell.execute_reply": "2024-05-28T01:39:28.775940Z",
     "shell.execute_reply.started": "2024-05-28T01:39:22.160287Z"
    },
    "id": "7_wOSAVFcrEm",
    "outputId": "2f364275-e675-4569-9518-00e8c88bcb40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " series_input (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " series_embedding (Embeddin  (None, None, 24)             672       ['series_input[0][0]']        \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                (None, None, 32)             7296      ['series_embedding[0][0]']    \n",
      "                                                                                                  \n",
      " mode_embedding (Embedding)  (None, 1, 6)                 54        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " lstm2 (LSTM)                (None, 32)                   8320      ['lstm1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_6 (TF  (None, 6)                    0         ['mode_embedding[0][0]']      \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " position_input (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, 39)                   0         ['lstm2[0][0]',               \n",
      "                                                                     'tf.compat.v1.squeeze_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'position_input[0][0]']      \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 64)                   2560      ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)          (None, 64)                   0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm1 (BatchNormaliz  (None, 64)                   256       ['dropout1[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 64)                   4160      ['batch_norm1[0][0]']         \n",
      "                                                                                                  \n",
      " dropout2 (Dropout)          (None, 64)                   0         ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm2 (BatchNormaliz  (None, 64)                   256       ['dropout2[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense3 (Dense)              (None, 64)                   4160      ['batch_norm2[0][0]']         \n",
      "                                                                                                  \n",
      " dropout3 (Dropout)          (None, 64)                   0         ['dense3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm3 (BatchNormaliz  (None, 64)                   256       ['dropout3[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 28)                   1820      ['batch_norm3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29810 (116.45 KB)\n",
      "Trainable params: 29426 (114.95 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "# Create a vocabulary and mode dictionary\n",
    "vocab = sorted(set([note for melody in melodies for note in melody]))\n",
    "vocab_dict = {note: i + 1 for i, note in enumerate(vocab)}  # Start indexing from 1 for padding\n",
    "vocab_size = len(vocab_dict) + 1  # +1 for padding\n",
    "\n",
    "mode_dict = {mode: i + 1 for i, mode in enumerate(sorted(set(modes)))}\n",
    "mode_vocab_size = len(mode_dict) + 1\n",
    "\n",
    "# Encode melodies and modes using dictionaries\n",
    "encoded_melodies = [[vocab_dict[note] for note in melody] for melody in melodies]\n",
    "encoded_modes = [mode_dict[mode] for mode in modes]\n",
    "\n",
    "# Create position input indicating how many elements are left until the end of the series\n",
    "positions = [[len(melody) - idx - 1 for idx in range(len(melody))] for melody in encoded_melodies]\n",
    "\n",
    "# Prepare data for the model\n",
    "X_series = []\n",
    "X_modes = []\n",
    "X_positions = []\n",
    "y = []\n",
    "\n",
    "for melody, mode, position in zip(encoded_melodies, encoded_modes, positions):\n",
    "    for i in range(1, len(melody)):\n",
    "        X_series.append(melody[:i])\n",
    "        X_modes.append([mode])\n",
    "        X_positions.append([position[i-1]])\n",
    "        y.append(melody[i])\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "X_series = tf.keras.preprocessing.sequence.pad_sequences(X_series, padding='pre')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_series = np.array(X_series)\n",
    "X_modes = np.array(X_modes)\n",
    "X_positions = np.array(X_positions)\n",
    "y = np.array(y)\n",
    "\n",
    "# Define cosine decay function for learning rate\n",
    "def cosine_decay(epoch, initial_lr):\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / epochs))\n",
    "    return initial_lr * cosine_decay\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 24\n",
    "lstm_units = 32\n",
    "mode_embedding_dim = 6\n",
    "dense_units = 64\n",
    "dropout_rate = 0.2\n",
    "initial_lr = 0.1\n",
    "epochs = 50\n",
    "\n",
    "# Input layers\n",
    "series_input = Input(shape=(None,), name='series_input')\n",
    "mode_input = Input(shape=(1,), name='mode_input')\n",
    "position_input = Input(shape=(1,), name='position_input')\n",
    "\n",
    "# Embedding layers\n",
    "series_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='series_embedding')(series_input)\n",
    "mode_embedding = Embedding(input_dim=mode_vocab_size, output_dim=mode_embedding_dim, name='mode_embedding')(mode_input)\n",
    "\n",
    "# LSTM layer\n",
    "lstm1 = LSTM(units=lstm_units, name='lstm1', return_sequences = True, dropout = 0, recurrent_dropout = 0)(series_embedding)\n",
    "lstm2 = LSTM(units=lstm_units, name='lstm2')(lstm1)\n",
    "\n",
    "# Concatenate embeddings and position input\n",
    "concatenated = Concatenate(name='concat_layer')([lstm2, tf.squeeze(mode_embedding, axis=1), position_input])\n",
    "\n",
    "# Dense layers with dropout and batch normalization\n",
    "dense1 = Dense(units=dense_units, activation='relu', name='dense1')(concatenated)\n",
    "dropout1 = Dropout(rate=dropout_rate, name='dropout1')(dense1)\n",
    "batch_norm1 = BatchNormalization(name='batch_norm1')(dropout1)\n",
    "\n",
    "dense2 = Dense(units=dense_units, activation='relu', name='dense2')(batch_norm1)\n",
    "dropout2 = Dropout(rate=dropout_rate, name='dropout2')(dense2)\n",
    "batch_norm2 = BatchNormalization(name='batch_norm2')(dropout2)\n",
    "\n",
    "\n",
    "dense3 = Dense(units=dense_units, activation='relu', name='dense3')(batch_norm2)\n",
    "dropout3 = Dropout(rate=dropout_rate, name='dropout3')(dense3)\n",
    "batch_norm3 = BatchNormalization(name='batch_norm3')(dropout3)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=vocab_size, activation='softmax', name='output')(batch_norm3)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=[series_input, mode_input, position_input], outputs=output, name='LSTM_Model')\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_scheduler = LearningRateScheduler(schedule=lambda epoch: cosine_decay(epoch, initial_lr))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T01:39:28.778354Z",
     "iopub.status.busy": "2024-05-28T01:39:28.778152Z",
     "iopub.status.idle": "2024-05-28T01:43:13.984145Z",
     "shell.execute_reply": "2024-05-28T01:43:13.982968Z",
     "shell.execute_reply.started": "2024-05-28T01:39:28.778335Z"
    },
    "id": "G9_9mRMhyvYu",
    "outputId": "c4a4eca3-a0f1-4e63-b0f8-a2b2b159c279",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10517/10517 [==============================] - 162s 15ms/step - loss: 1.7588 - accuracy: 0.3068 - val_loss: 74.7861 - val_accuracy: 0.3593 - lr: 0.1000\n",
      "Epoch 2/50\n",
      " 4596/10517 [============>.................] - ETA: 1:20 - loss: 1.7522 - accuracy: 0.3146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_positions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit([X_series, X_modes, X_positions], y,\n",
    "          validation_split=0.2, epochs=epochs, batch_size=64,\n",
    "          callbacks=[early_stopping, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-05-28T01:43:13.985045Z",
     "iopub.status.idle": "2024-05-28T01:43:13.985276Z",
     "shell.execute_reply": "2024-05-28T01:43:13.985178Z",
     "shell.execute_reply.started": "2024-05-28T01:43:13.985167Z"
    },
    "id": "p12jdV3Z59XH",
    "outputId": "f3366c60-3c50-43f4-9950-0e6a7b28f2e4"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/melody_prediction_model_with_notes_until_end.h5')\n",
    "\n",
    "# Save the dictionaries\n",
    "with open('models/pitch_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_dict, f)\n",
    "\n",
    "with open('models/mode_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(mode_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-05-28T01:43:13.986330Z",
     "iopub.status.idle": "2024-05-28T01:43:13.986558Z",
     "shell.execute_reply": "2024-05-28T01:43:13.986460Z",
     "shell.execute_reply.started": "2024-05-28T01:43:13.986449Z"
    },
    "id": "rjviivZS59UA",
    "outputId": "e5978eee-a9c2-4f65-cf08-4a092f82049c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Function to load the model and dictionaries\n",
    "def load_resources(model_path, vocab_dict_path, mode_dict_path):\n",
    "    model = load_model(model_path)\n",
    "    with open(vocab_dict_path, 'rb') as f:\n",
    "        vocab_dict = pickle.load(f)\n",
    "    with open(mode_dict_path, 'rb') as f:\n",
    "        mode_dict = pickle.load(f)\n",
    "    return model, vocab_dict, mode_dict\n",
    "\n",
    "# Function to predict the element probabilities for a given sequence, mode, and remaining notes\n",
    "def predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict):\n",
    "    # Reverse the vocab_dict to get the reverse mapping from indices to elements\n",
    "    index_to_vocab = {index: element for element, index in vocab_dict.items()}\n",
    "\n",
    "    # Encode the sequence and mode using the dictionaries\n",
    "    encoded_sequence = [vocab_dict[element] for element in sequence]\n",
    "    encoded_mode = np.array([mode_dict[mode]]).reshape(1, 1)\n",
    "\n",
    "    # Create the position input based on the notes left in the series\n",
    "    position_input = np.array([[notes_left]])\n",
    "\n",
    "    # Pad the sequence to match the input shape of the model\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([encoded_sequence], padding='pre')\n",
    "\n",
    "    # Predict the probabilities\n",
    "    probabilities = model.predict([padded_sequence, encoded_mode, position_input])[0]\n",
    "\n",
    "    # Map the probabilities back to the elements\n",
    "    element_probabilities = {index_to_vocab[i]: prob for i, prob in enumerate(probabilities) if i in index_to_vocab}\n",
    "\n",
    "    return element_probabilities\n",
    "\n",
    "# Function to extend a sequence to a specified length using temperature-controlled sampling\n",
    "def extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict):\n",
    "    sequence = initial_sequence[:]\n",
    "    while len(sequence) < target_length:\n",
    "        notes_left = target_length - len(sequence)\n",
    "        element_probabilities = predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict)\n",
    "\n",
    "        # Sort elements by probability\n",
    "        sorted_elements = sorted(element_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Determine the number of elements to sample from based on temperature\n",
    "        num_elements = int(len(sorted_elements) * temperature)\n",
    "        num_elements = max(1, num_elements)  # Ensure at least one element is sampled\n",
    "\n",
    "        # Sample the next element based on the adjusted probabilities\n",
    "        elements, probabilities = zip(*sorted_elements[:num_elements])\n",
    "        probabilities = np.array(probabilities) / np.sum(probabilities)  # Normalize probabilities\n",
    "        next_element = np.random.choice(elements, p=probabilities)\n",
    "\n",
    "        # Append the next element to the sequence\n",
    "        sequence.append(next_element)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Load resources\n",
    "model, vocab_dict, mode_dict = load_resources('models/v2/melody_prediction_model_with_notes_until_end.h5',\n",
    "                                              'models/v2/pitch_encoder.pkl',\n",
    "                                              'models/v2/mode_encoder.pkl')\n",
    "\n",
    "# Example usage\n",
    "initial_sequence = [\"F4\", \"E4\"]\n",
    "mode = \"1\"\n",
    "target_length = 16\n",
    "temperature = 0.5  # Specify the temperature value\n",
    "extended_sequence = extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict)\n",
    "\n",
    "print(\"Extended Sequence:\", extended_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNF2alsS9Nc-"
   },
   "outputs": [],
   "source": [
    "melody_to_midi(extended_sequence,[1, 1, 1], [127, 70, 100, 50], \"generated_melody.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGJRCWVsBdY2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
