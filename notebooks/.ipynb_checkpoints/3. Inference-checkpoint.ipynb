{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya6joXh6kXJd",
        "outputId": "27838091-b3f1-479b-de0c-8b5902aff36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting midiutil\n",
            "  Downloading MIDIUtil-1.2.1.tar.gz (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: midiutil\n",
            "  Building wheel for midiutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for midiutil: filename=MIDIUtil-1.2.1-py3-none-any.whl size=54567 sha256=b56845e31c599768deba1678cfb5157a7b40dd5e917f1572ab0eb8af2c6335fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/43/4a/00b5e4f2fe5e2cd6e92b461995a3a97a2cebb30ab5783501b0\n",
            "Successfully built midiutil\n",
            "Installing collected packages: midiutil\n",
            "Successfully installed midiutil-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install midiutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from midiutil import MIDIFile\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle"
      ],
      "metadata": {
        "id": "PMD4Kl8RkaMN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('drive/MyDrive/ChantAI')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9IzEJOCkcLz",
        "outputId": "225674eb-82a0-46a8-8e87-cf2911b65e2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def note_to_midi(note, octave):\n",
        "    # MIDI note numbers for the notes in octave 0\n",
        "    note_map = {\n",
        "        'c': 0, 'c#': 1, 'd': 2, 'd#': 3, 'e': 4, 'f': 5, 'f#': 6,\n",
        "        'g': 7, 'g#': 8, 'a': 9, 'a#': 10, 'b': 11\n",
        "    }\n",
        "\n",
        "    # Convert note to lowercase to handle both upper and lower case inputs\n",
        "    note = note.lower()\n",
        "\n",
        "    # Calculate the MIDI number\n",
        "    midi_number = (octave + 1) * 12 + note_map[note]\n",
        "\n",
        "    return midi_number\n",
        "\n",
        "def melody_to_midi(melody, rhythm_pattern, velocity_pattern, filename):\n",
        "    midi = MIDIFile(1)\n",
        "    midi.addTempo(0, 0, 120)\n",
        "\n",
        "    for i, note in enumerate(melody):\n",
        "        pitch_class = note[:-1]\n",
        "        octave = note[-1]\n",
        "        pitch = note_to_midi(pitch_class.lower(), int(octave))\n",
        "        duration = rhythm_pattern[i % len(rhythm_pattern)]\n",
        "        velocity = velocity_pattern[i % len(velocity_pattern)]\n",
        "        midi.addNote(0, 0, pitch, i, duration, velocity)  # Add note with duration of 1\n",
        "\n",
        "    with open(filename, 'wb') as output_file:\n",
        "        midi.writeFile(output_file)\n",
        "\n",
        "# Function to load the model and dictionaries\n",
        "def load_resources(model_path, vocab_dict_path, mode_dict_path):\n",
        "    model = load_model(model_path)\n",
        "    with open(vocab_dict_path, 'rb') as f:\n",
        "        vocab_dict = pickle.load(f)\n",
        "    with open(mode_dict_path, 'rb') as f:\n",
        "        mode_dict = pickle.load(f)\n",
        "    return model, vocab_dict, mode_dict\n",
        "\n",
        "# Function to predict the element probabilities for a given sequence, mode, and remaining notes\n",
        "def predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict):\n",
        "    # Reverse the vocab_dict to get the reverse mapping from indices to elements\n",
        "    index_to_vocab = {index: element for element, index in vocab_dict.items()}\n",
        "\n",
        "    # Encode the sequence and mode using the dictionaries\n",
        "    encoded_sequence = [vocab_dict[element] for element in sequence]\n",
        "    encoded_mode = np.array([mode_dict[mode]]).reshape(1, 1)\n",
        "\n",
        "    # Create the position input based on the notes left in the series\n",
        "    position_input = np.array([[notes_left]])\n",
        "\n",
        "    # Pad the sequence to match the input shape of the model\n",
        "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([encoded_sequence], padding='pre')\n",
        "\n",
        "    # Predict the probabilities\n",
        "    probabilities = model.predict([padded_sequence, encoded_mode, position_input])[0]\n",
        "\n",
        "    # Map the probabilities back to the elements\n",
        "    element_probabilities = {index_to_vocab[i]: prob for i, prob in enumerate(probabilities) if i in index_to_vocab}\n",
        "\n",
        "    return element_probabilities\n",
        "\n",
        "# Function to extend a sequence to a specified length using temperature-controlled sampling\n",
        "def extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict):\n",
        "    sequence = initial_sequence[:]\n",
        "    while len(sequence) < target_length:\n",
        "        notes_left = target_length - len(sequence)\n",
        "        element_probabilities = predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict)\n",
        "\n",
        "        # Sort elements by probability\n",
        "        sorted_elements = sorted(element_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "        # Determine the number of elements to sample from based on temperature\n",
        "        num_elements = int(len(sorted_elements) * temperature)\n",
        "        num_elements = max(1, num_elements)  # Ensure at least one element is sampled\n",
        "\n",
        "        # Sample the next element based on the adjusted probabilities\n",
        "        elements, probabilities = zip(*sorted_elements[:num_elements])\n",
        "        probabilities = np.array(probabilities) / np.sum(probabilities)  # Normalize probabilities\n",
        "        next_element = np.random.choice(elements, p=probabilities)\n",
        "\n",
        "        # Append the next element to the sequence\n",
        "        sequence.append(next_element)\n",
        "\n",
        "    return sequence"
      ],
      "metadata": {
        "id": "Y5gDtIeDkdxH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_dorian = pd.read_csv('data/antiphon_melodies.csv')\n",
        "tb_dorian = tb_dorian[tb_dorian['mode'].isin([str(x) for x in range(1, 9)])].dropna()\n",
        "unique_ids = tb_dorian.groupby('id')['notes'].apply(list).reset_index().drop_duplicates(subset = 'notes')['id'].tolist()\n",
        "tb_dorian = tb_dorian[tb_dorian['id'].isin(unique_ids)]\n",
        "test_set = np.random.choice(unique_ids, 100, replace = False)\n",
        "train_data = tb_dorian[~tb_dorian['id'].isin(test_set)]\n",
        "test_data = tb_dorian[tb_dorian['id'].isin(test_set)]\n",
        "melodies = train_data.groupby('id')['notes'].apply(list).tolist()\n",
        "modes = train_data.groupby('id')['mode'].first().to_list()"
      ],
      "metadata": {
        "id": "HujD4UJckwDo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load resources\n",
        "model, vocab_dict, mode_dict = load_resources('models/v2/melody_prediction_model_with_notes_until_end.h5',\n",
        "                                              'models/v2/pitch_encoder.pkl',\n",
        "                                              'models/v2/mode_encoder.pkl')"
      ],
      "metadata": {
        "id": "cz41JiD0klzp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "initial_sequence = [\"F4\", \"E4\"]\n",
        "mode = \"2\"\n",
        "target_length = 16\n",
        "temperature = 0.5  # Specify the temperature value\n",
        "final_sequence = []\n",
        "for i in range(5):\n",
        "  if i == 0:\n",
        "    extended_sequence = extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict)\n",
        "  else:\n",
        "    extended_sequence = extend_sequence(extended_sequence[-4:], mode, target_length, temperature, model, vocab_dict, mode_dict)\n",
        "  final_sequence.extend(extended_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvxCZXc3klrl",
        "outputId": "82adf395-2306-4a3c-811f-a015d3681ee1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melody_to_midi(final_sequence,[1, 1, 1], [127, 70, 100, 50], \"hypodorian_antiphon.mid\")"
      ],
      "metadata": {
        "id": "ER1o7q78l0Qw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(melodies, modes))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y9eSdJcnMB-",
        "outputId": "b801f26b-1b69-4f02-b41f-22185582dcb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['A4', 'G4', 'G4', 'G4', 'D5', 'D5', 'E5', 'D5', 'C5', 'B4', 'C5'], '7')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar = list(filter(lambda x: x[0][0:2] == initial_sequence and x[1] == mode, zip(melodies, modes)))"
      ],
      "metadata": {
        "id": "T8ehzrZ3mB7k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melody_to_midi(similar[0][0],[1, 1, 1], [127, 70, 100, 50], \"og1_hypodorian_antiphon.mid\")"
      ],
      "metadata": {
        "id": "ujUaOSEHnnSG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtYJQWyLnyyp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}