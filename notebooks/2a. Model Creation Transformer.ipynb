{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:59:00.467810Z",
     "iopub.status.busy": "2024-05-28T05:59:00.467264Z",
     "iopub.status.idle": "2024-05-28T05:59:06.605296Z",
     "shell.execute_reply": "2024-05-28T05:59:06.604645Z",
     "shell.execute_reply.started": "2024-05-28T05:59:00.467788Z"
    },
    "id": "J5VUMSA34aq7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 05:59:02.011179: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-28 05:59:02.011230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-28 05:59:02.012423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-28 05:59:02.019531: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 05:59:04.593359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from midiutil import MIDIFile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T07:41:38.993582Z",
     "iopub.status.busy": "2024-05-28T07:41:38.992920Z",
     "iopub.status.idle": "2024-05-28T07:41:38.999137Z",
     "shell.execute_reply": "2024-05-28T07:41:38.998396Z",
     "shell.execute_reply.started": "2024-05-28T07:41:38.993560Z"
    },
    "id": "kVW2ouKw1r1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def note_to_midi(note, octave):\n",
    "    # MIDI note numbers for the notes in octave 0\n",
    "    note_map = {\n",
    "        'c': 0, 'c#': 1, 'd': 2, 'd#': 3, 'e': 4, 'f': 5, 'f#': 6,\n",
    "        'g': 7, 'g#': 8, 'a': 9, 'a#': 10, 'b': 11\n",
    "    }\n",
    "\n",
    "    # Convert note to lowercase to handle both upper and lower case inputs\n",
    "    note = note.lower()\n",
    "\n",
    "    # Calculate the MIDI number\n",
    "    midi_number = (octave + 1) * 12 + note_map[note]\n",
    "\n",
    "    return midi_number\n",
    "\n",
    "def melody_to_midi(melody, rhythm_pattern, velocity_pattern, filename):\n",
    "    midi = MIDIFile(1)\n",
    "    midi.addTempo(0, 0, 120)\n",
    "\n",
    "    for i, note in enumerate(melody):\n",
    "        pitch_class = note[:-1]\n",
    "        octave = note[-1]\n",
    "        pitch = note_to_midi(pitch_class.lower(), int(octave))\n",
    "        duration = rhythm_pattern[i % len(rhythm_pattern)]\n",
    "        velocity = velocity_pattern[i % len(velocity_pattern)]\n",
    "        midi.addNote(0, 0, pitch, i, duration, velocity)  # Add note with duration of 1\n",
    "\n",
    "    with open(filename, 'wb') as output_file:\n",
    "        midi.writeFile(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:59:06.614767Z",
     "iopub.status.busy": "2024-05-28T05:59:06.614286Z",
     "iopub.status.idle": "2024-05-28T05:59:06.618209Z",
     "shell.execute_reply": "2024-05-28T05:59:06.617506Z",
     "shell.execute_reply.started": "2024-05-28T05:59:06.614737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/jovyan/workspace/cantus_ai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T07:53:12.927827Z",
     "iopub.status.busy": "2024-05-28T07:53:12.927310Z",
     "iopub.status.idle": "2024-05-28T07:53:32.705372Z",
     "shell.execute_reply": "2024-05-28T07:53:32.704607Z",
     "shell.execute_reply.started": "2024-05-28T07:53:12.927803Z"
    },
    "id": "w_vDc2kk7bIO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_chants = pd.read_csv('output/office_melodies.csv')\n",
    "tb_chants = tb_chants[tb_chants['mode'].isin([str(x) for x in range(1, 9)])].dropna()\n",
    "unique_ids = tb_chants.groupby('id')['notes'].apply(list).reset_index().drop_duplicates(subset = 'notes')['id'].tolist()\n",
    "tb_chants = tb_chants[tb_chants['id'].isin(unique_ids)]\n",
    "test_set = np.random.choice(unique_ids, 100, replace = False)\n",
    "train_data = tb_chants[~tb_chants['id'].isin(test_set)]\n",
    "test_data = tb_chants[tb_chants['id'].isin(test_set)]\n",
    "melodies = train_data.groupby('id')['notes'].apply(list).tolist()\n",
    "modes = train_data.groupby('id')['mode'].first().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T09:02:05.609209Z",
     "iopub.status.busy": "2024-05-28T09:02:05.608800Z",
     "iopub.status.idle": "2024-05-28T09:02:24.795611Z",
     "shell.execute_reply": "2024-05-28T09:02:24.794754Z",
     "shell.execute_reply.started": "2024-05-28T09:02:05.609187Z"
    },
    "id": "7_wOSAVFcrEm",
    "outputId": "2f364275-e675-4569-9518-00e8c88bcb40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " series_input (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " series_embedding (Embeddin  (None, None, 24)             720       ['series_input[0][0]']        \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                (None, None, 32)             7296      ['series_embedding[0][0]']    \n",
      "                                                                                                  \n",
      " mode_embedding (Embedding)  (None, 1, 6)                 54        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " lstm2 (LSTM)                (None, 32)                   8320      ['lstm1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_5 (TF  (None, 6)                    0         ['mode_embedding[0][0]']      \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " position_input (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, 39)                   0         ['lstm2[0][0]',               \n",
      "                                                                     'tf.compat.v1.squeeze_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'position_input[0][0]']      \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 64)                   2560      ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)          (None, 64)                   0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm1 (BatchNormaliz  (None, 64)                   256       ['dropout1[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 64)                   4160      ['batch_norm1[0][0]']         \n",
      "                                                                                                  \n",
      " dropout2 (Dropout)          (None, 64)                   0         ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm2 (BatchNormaliz  (None, 64)                   256       ['dropout2[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense3 (Dense)              (None, 64)                   4160      ['batch_norm2[0][0]']         \n",
      "                                                                                                  \n",
      " dropout3 (Dropout)          (None, 64)                   0         ['dense3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm3 (BatchNormaliz  (None, 64)                   256       ['dropout3[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 30)                   1950      ['batch_norm3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29988 (117.14 KB)\n",
      "Trainable params: 29604 (115.64 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "# Create a vocabulary and mode dictionary\n",
    "vocab = sorted(set([note for melody in melodies for note in melody]))\n",
    "vocab_dict = {note: i + 1 for i, note in enumerate(vocab)}  # Start indexing from 1 for padding\n",
    "vocab_size = len(vocab_dict) + 1  # +1 for padding\n",
    "\n",
    "mode_dict = {mode: i + 1 for i, mode in enumerate(sorted(set(modes)))}\n",
    "mode_vocab_size = len(mode_dict) + 1\n",
    "\n",
    "# Encode melodies and modes using dictionaries\n",
    "encoded_melodies = [[vocab_dict[note] for note in melody] for melody in melodies]\n",
    "encoded_modes = [mode_dict[mode] for mode in modes]\n",
    "\n",
    "# Create position input indicating how many elements are left until the end of the series\n",
    "positions = [[len(melody) - idx - 1 for idx in range(len(melody))] for melody in encoded_melodies]\n",
    "\n",
    "# Prepare data for the model\n",
    "X_series = []\n",
    "X_modes = []\n",
    "X_positions = []\n",
    "y = []\n",
    "\n",
    "for melody, mode, position in zip(encoded_melodies, encoded_modes, positions):\n",
    "    for i in range(1, len(melody)):\n",
    "        X_series.append(melody[:i])\n",
    "        X_modes.append([mode])\n",
    "        X_positions.append([position[i-1]])\n",
    "        y.append(melody[i])\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "X_series = tf.keras.preprocessing.sequence.pad_sequences(X_series, padding='pre')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_series = np.array(X_series)\n",
    "X_modes = np.array(X_modes)\n",
    "X_positions = np.array(X_positions)\n",
    "y = np.array(y)\n",
    "\n",
    "# Define cosine decay function for learning rate\n",
    "def cosine_decay(epoch, initial_lr):\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / epochs))\n",
    "    return initial_lr * cosine_decay\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 24\n",
    "lstm_units = 32\n",
    "mode_embedding_dim = 6\n",
    "dense_units = 64\n",
    "dropout_rate = 0.2\n",
    "initial_lr = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Input layers\n",
    "series_input = Input(shape=(None,), name='series_input')\n",
    "mode_input = Input(shape=(1,), name='mode_input')\n",
    "position_input = Input(shape=(1,), name='position_input')\n",
    "\n",
    "# Embedding layers\n",
    "series_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='series_embedding')(series_input)\n",
    "mode_embedding = Embedding(input_dim=mode_vocab_size, output_dim=mode_embedding_dim, name='mode_embedding')(mode_input)\n",
    "\n",
    "# LSTM layer\n",
    "lstm1 = LSTM(units=lstm_units, name='lstm1', return_sequences = True, dropout = 0, recurrent_dropout = 0)(series_embedding)\n",
    "lstm2 = LSTM(units=lstm_units, name='lstm2')(lstm1)\n",
    "\n",
    "# Concatenate embeddings and position input\n",
    "concatenated = Concatenate(name='concat_layer')([lstm2, tf.squeeze(mode_embedding, axis=1), position_input])\n",
    "\n",
    "# Dense layers with dropout and batch normalization\n",
    "dense1 = Dense(units=dense_units, activation='relu', name='dense1')(concatenated)\n",
    "dropout1 = Dropout(rate=dropout_rate, name='dropout1')(dense1)\n",
    "batch_norm1 = BatchNormalization(name='batch_norm1')(dropout1)\n",
    "\n",
    "dense2 = Dense(units=dense_units, activation='relu', name='dense2')(batch_norm1)\n",
    "dropout2 = Dropout(rate=dropout_rate, name='dropout2')(dense2)\n",
    "batch_norm2 = BatchNormalization(name='batch_norm2')(dropout2)\n",
    "\n",
    "\n",
    "dense3 = Dense(units=dense_units, activation='relu', name='dense3')(batch_norm2)\n",
    "dropout3 = Dropout(rate=dropout_rate, name='dropout3')(dense3)\n",
    "batch_norm3 = BatchNormalization(name='batch_norm3')(dropout3)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=vocab_size, activation='softmax', name='output')(batch_norm3)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=[series_input, mode_input, position_input], outputs=output, name='LSTM_Model')\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = LearningRateScheduler(schedule=lambda epoch: cosine_decay(epoch, initial_lr))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T09:02:24.797172Z",
     "iopub.status.busy": "2024-05-28T09:02:24.796981Z"
    },
    "id": "G9_9mRMhyvYu",
    "outputId": "c4a4eca3-a0f1-4e63-b0f8-a2b2b159c279",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27721/27721 [==============================] - 475s 17ms/step - loss: 1.4658 - accuracy: 0.4195 - val_loss: 1.3130 - val_accuracy: 0.4913 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.3245 - accuracy: 0.4915 - val_loss: 1.2481 - val_accuracy: 0.5209 - lr: 9.9901e-04\n",
      "Epoch 3/50\n",
      "27721/27721 [==============================] - 469s 17ms/step - loss: 1.2753 - accuracy: 0.5155 - val_loss: 1.2146 - val_accuracy: 0.5353 - lr: 9.9606e-04\n",
      "Epoch 4/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.2490 - accuracy: 0.5262 - val_loss: 1.2004 - val_accuracy: 0.5403 - lr: 9.9114e-04\n",
      "Epoch 5/50\n",
      "27721/27721 [==============================] - 469s 17ms/step - loss: 1.2311 - accuracy: 0.5332 - val_loss: 1.1895 - val_accuracy: 0.5427 - lr: 9.8429e-04\n",
      "Epoch 6/50\n",
      "27721/27721 [==============================] - 469s 17ms/step - loss: 1.2195 - accuracy: 0.5376 - val_loss: 1.1842 - val_accuracy: 0.5454 - lr: 9.7553e-04\n",
      "Epoch 7/50\n",
      "27721/27721 [==============================] - 469s 17ms/step - loss: 1.2097 - accuracy: 0.5412 - val_loss: 1.2013 - val_accuracy: 0.5381 - lr: 9.6489e-04\n",
      "Epoch 8/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.2041 - accuracy: 0.5436 - val_loss: 1.1785 - val_accuracy: 0.5463 - lr: 9.5241e-04\n",
      "Epoch 9/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1984 - accuracy: 0.5457 - val_loss: 1.1669 - val_accuracy: 0.5499 - lr: 9.3815e-04\n",
      "Epoch 10/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1929 - accuracy: 0.5479 - val_loss: 1.1629 - val_accuracy: 0.5535 - lr: 9.2216e-04\n",
      "Epoch 11/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1887 - accuracy: 0.5494 - val_loss: 1.1603 - val_accuracy: 0.5543 - lr: 9.0451e-04\n",
      "Epoch 12/50\n",
      "27721/27721 [==============================] - 469s 17ms/step - loss: 1.1849 - accuracy: 0.5508 - val_loss: 1.1530 - val_accuracy: 0.5561 - lr: 8.8526e-04\n",
      "Epoch 13/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1812 - accuracy: 0.5528 - val_loss: 1.1560 - val_accuracy: 0.5561 - lr: 8.6448e-04\n",
      "Epoch 14/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1782 - accuracy: 0.5539 - val_loss: 1.1558 - val_accuracy: 0.5557 - lr: 8.4227e-04\n",
      "Epoch 15/50\n",
      "27721/27721 [==============================] - 471s 17ms/step - loss: 1.1752 - accuracy: 0.5552 - val_loss: 1.1532 - val_accuracy: 0.5571 - lr: 8.1871e-04\n",
      "Epoch 16/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1716 - accuracy: 0.5571 - val_loss: 1.1479 - val_accuracy: 0.5602 - lr: 7.9389e-04\n",
      "Epoch 17/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1695 - accuracy: 0.5576 - val_loss: 1.1438 - val_accuracy: 0.5613 - lr: 7.6791e-04\n",
      "Epoch 18/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1671 - accuracy: 0.5588 - val_loss: 1.1487 - val_accuracy: 0.5587 - lr: 7.4088e-04\n",
      "Epoch 19/50\n",
      "27721/27721 [==============================] - 470s 17ms/step - loss: 1.1652 - accuracy: 0.5596 - val_loss: 1.1446 - val_accuracy: 0.5619 - lr: 7.1289e-04\n",
      "Epoch 20/50\n",
      "17235/27721 [=================>............] - ETA: 2:42 - loss: 1.1617 - accuracy: 0.5604"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit([X_series, X_modes, X_positions], y,\n",
    "          validation_split=0.2, epochs=epochs, batch_size=64,\n",
    "          callbacks=[early_stopping, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p12jdV3Z59XH",
    "outputId": "f3366c60-3c50-43f4-9950-0e6a7b28f2e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/office/melody_prediction_model_with_notes_until_end.h5')\n",
    "\n",
    "# Save the dictionaries\n",
    "with open('models/office/pitch_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_dict, f)\n",
    "\n",
    "with open('models/office/mode_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(mode_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T07:50:12.475224Z",
     "iopub.status.busy": "2024-05-28T07:50:12.474646Z",
     "iopub.status.idle": "2024-05-28T07:50:14.688552Z",
     "shell.execute_reply": "2024-05-28T07:50:14.687790Z",
     "shell.execute_reply.started": "2024-05-28T07:50:12.475201Z"
    },
    "id": "rjviivZS59UA",
    "outputId": "e5978eee-a9c2-4f65-cf08-4a092f82049c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 512ms/step\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Extended Sequence: ['F4', 'E4', 'D4', 'D4', 'G4', 'F4', 'F4', 'G4', 'F4', 'A4', 'G4', 'F4', 'D4', 'D4', 'F4', 'F4']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Function to load the model and dictionaries\n",
    "def load_resources(model_path, vocab_dict_path, mode_dict_path):\n",
    "    model = load_model(model_path)\n",
    "    with open(vocab_dict_path, 'rb') as f:\n",
    "        vocab_dict = pickle.load(f)\n",
    "    with open(mode_dict_path, 'rb') as f:\n",
    "        mode_dict = pickle.load(f)\n",
    "    return model, vocab_dict, mode_dict\n",
    "\n",
    "# Function to predict the element probabilities for a given sequence, mode, and remaining notes\n",
    "def predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict):\n",
    "    # Reverse the vocab_dict to get the reverse mapping from indices to elements\n",
    "    index_to_vocab = {index: element for element, index in vocab_dict.items()}\n",
    "\n",
    "    # Encode the sequence and mode using the dictionaries\n",
    "    encoded_sequence = [vocab_dict[element] for element in sequence]\n",
    "    encoded_mode = np.array([mode_dict[mode]]).reshape(1, 1)\n",
    "\n",
    "    # Create the position input based on the notes left in the series\n",
    "    position_input = np.array([[notes_left]])\n",
    "\n",
    "    # Pad the sequence to match the input shape of the model\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([encoded_sequence], padding='pre')\n",
    "\n",
    "    # Predict the probabilities\n",
    "    probabilities = model.predict([padded_sequence, encoded_mode, position_input])[0]\n",
    "\n",
    "    # Map the probabilities back to the elements\n",
    "    element_probabilities = {index_to_vocab[i]: prob for i, prob in enumerate(probabilities) if i in index_to_vocab}\n",
    "\n",
    "    return element_probabilities\n",
    "\n",
    "# Function to extend a sequence to a specified length using temperature-controlled sampling\n",
    "def extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict):\n",
    "    sequence = initial_sequence[:]\n",
    "    while len(sequence) < target_length:\n",
    "        notes_left = target_length - len(sequence)\n",
    "        element_probabilities = predict_element_probabilities(sequence, mode, notes_left, model, vocab_dict, mode_dict)\n",
    "\n",
    "        # Sort elements by probability\n",
    "        sorted_elements = sorted(element_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Determine the number of elements to sample from based on temperature\n",
    "        num_elements = int(len(sorted_elements) * temperature)\n",
    "        num_elements = max(1, num_elements)  # Ensure at least one element is sampled\n",
    "\n",
    "        # Sample the next element based on the adjusted probabilities\n",
    "        elements, probabilities = zip(*sorted_elements[:num_elements])\n",
    "        probabilities = np.array(probabilities) / np.sum(probabilities)  # Normalize probabilities\n",
    "        next_element = np.random.choice(elements, p=probabilities)\n",
    "\n",
    "        # Append the next element to the sequence\n",
    "        sequence.append(next_element)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Load resources\n",
    "model, vocab_dict, mode_dict = load_resources('models/mass/melody_prediction_model_with_notes_until_end.h5',\n",
    "                                              'models/mass/pitch_encoder.pkl',\n",
    "                                              'models/mass/mode_encoder.pkl')\n",
    "\n",
    "# Example usage\n",
    "initial_sequence = [\"F4\", \"E4\"]\n",
    "mode = \"2\"\n",
    "target_length = 16\n",
    "temperature = 0.5  # Specify the temperature value\n",
    "extended_sequence = extend_sequence(initial_sequence, mode, target_length, temperature, model, vocab_dict, mode_dict)\n",
    "\n",
    "print(\"Extended Sequence:\", extended_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T07:50:17.818140Z",
     "iopub.status.busy": "2024-05-28T07:50:17.817754Z",
     "iopub.status.idle": "2024-05-28T07:50:17.822753Z",
     "shell.execute_reply": "2024-05-28T07:50:17.821993Z",
     "shell.execute_reply.started": "2024-05-28T07:50:17.818117Z"
    },
    "id": "UNF2alsS9Nc-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "melody_to_midi(extended_sequence,[1, 1, 1], [127, 70, 100, 50], \"generated_melody.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGJRCWVsBdY2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
