{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:23:13.882059Z",
     "iopub.status.busy": "2024-05-28T13:23:13.881459Z",
     "iopub.status.idle": "2024-05-28T13:23:20.212935Z",
     "shell.execute_reply": "2024-05-28T13:23:20.212326Z",
     "shell.execute_reply.started": "2024-05-28T13:23:13.882036Z"
    },
    "id": "J5VUMSA34aq7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from midiutil import MIDIFile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:23:20.214870Z",
     "iopub.status.busy": "2024-05-28T13:23:20.214397Z",
     "iopub.status.idle": "2024-05-28T13:23:20.220194Z",
     "shell.execute_reply": "2024-05-28T13:23:20.219539Z",
     "shell.execute_reply.started": "2024-05-28T13:23:20.214850Z"
    },
    "id": "kVW2ouKw1r1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def note_to_midi(note, octave):\n",
    "    # MIDI note numbers for the notes in octave 0\n",
    "    note_map = {\n",
    "        'c': 0, 'c#': 1, 'd': 2, 'd#': 3, 'e': 4, 'f': 5, 'f#': 6,\n",
    "        'g': 7, 'g#': 8, 'a': 9, 'a#': 10, 'b': 11\n",
    "    }\n",
    "\n",
    "    # Convert note to lowercase to handle both upper and lower case inputs\n",
    "    note = note.lower()\n",
    "\n",
    "    # Calculate the MIDI number\n",
    "    midi_number = (octave + 1) * 12 + note_map[note]\n",
    "\n",
    "    return midi_number\n",
    "\n",
    "def melody_to_midi(melody, rhythm_pattern, velocity_pattern, filename):\n",
    "    midi = MIDIFile(1)\n",
    "    midi.addTempo(0, 0, 120)\n",
    "\n",
    "    for i, note in enumerate(melody):\n",
    "        pitch_class = note[:-1]\n",
    "        octave = note[-1]\n",
    "        pitch = note_to_midi(pitch_class.lower(), int(octave))\n",
    "        duration = rhythm_pattern[i % len(rhythm_pattern)]\n",
    "        velocity = velocity_pattern[i % len(velocity_pattern)]\n",
    "        midi.addNote(0, 0, pitch, i, duration, velocity)  # Add note with duration of 1\n",
    "\n",
    "    with open(filename, 'wb') as output_file:\n",
    "        midi.writeFile(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:23:20.221160Z",
     "iopub.status.busy": "2024-05-28T13:23:20.220968Z",
     "iopub.status.idle": "2024-05-28T13:23:20.225081Z",
     "shell.execute_reply": "2024-05-28T13:23:20.224334Z",
     "shell.execute_reply.started": "2024-05-28T13:23:20.221136Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/jovyan/workspace/cantus_ai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"antiphon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:24:30.863476Z",
     "iopub.status.busy": "2024-05-28T13:24:30.862877Z",
     "iopub.status.idle": "2024-05-28T13:24:31.215602Z",
     "shell.execute_reply": "2024-05-28T13:24:31.214861Z",
     "shell.execute_reply.started": "2024-05-28T13:24:30.863454Z"
    },
    "id": "w_vDc2kk7bIO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_chants = pd.read_csv(f'output/{MODEL}_melodies.csv')\n",
    "tb_chants = tb_chants[tb_chants['mode'].isin([str(x) for x in range(1, 9)])].dropna()\n",
    "unique_ids = tb_chants.groupby('id')['notes'].apply(list).reset_index().drop_duplicates(subset = 'notes')['id'].tolist()\n",
    "tb_chants = tb_chants[tb_chants['id'].isin(unique_ids)]\n",
    "test_set = np.random.choice(unique_ids, 100, replace = False)\n",
    "train_data = tb_chants[~tb_chants['id'].isin(test_set)]\n",
    "test_data = tb_chants[tb_chants['id'].isin(test_set)]\n",
    "melodies = train_data.groupby('id')['notes'].apply(list).tolist()\n",
    "modes = train_data.groupby('id')['mode'].first().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:38:17.539719Z",
     "iopub.status.busy": "2024-05-28T13:38:17.539286Z",
     "iopub.status.idle": "2024-05-28T13:38:19.327957Z",
     "shell.execute_reply": "2024-05-28T13:38:19.327295Z",
     "shell.execute_reply.started": "2024-05-28T13:38:17.539698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "# Create a vocabulary and mode dictionary\n",
    "vocab = sorted(set([note for melody in melodies for note in melody]))\n",
    "vocab_dict = {note: i + 1 for i, note in enumerate(vocab)}  # Start indexing from 1 for padding\n",
    "vocab_size = len(vocab_dict) + 1  # +1 for padding\n",
    "\n",
    "mode_dict = {mode: i + 1 for i, mode in enumerate(sorted(set(modes)))}\n",
    "mode_vocab_size = len(mode_dict) + 1\n",
    "\n",
    "# Encode melodies and modes using dictionaries\n",
    "encoded_melodies = [[vocab_dict[note] for note in melody] for melody in melodies]\n",
    "encoded_modes = [mode_dict[mode] for mode in modes]\n",
    "\n",
    "# Create position input indicating how many elements are left until the end of the series\n",
    "positions = [[len(melody) - idx - 1 for idx in range(len(melody))] for melody in encoded_melodies]\n",
    "\n",
    "# Prepare data for the model\n",
    "X_series = []\n",
    "X_modes = []\n",
    "X_positions = []\n",
    "y = []\n",
    "\n",
    "for melody, mode, position in zip(encoded_melodies, encoded_modes, positions):\n",
    "    for i in range(1, len(melody)):\n",
    "        X_series.append(melody[:i])\n",
    "        X_modes.append([mode])\n",
    "        X_positions.append([position[i-1]])\n",
    "        y.append(melody[i])\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "X_series = tf.keras.preprocessing.sequence.pad_sequences(X_series, padding='pre')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_series = np.array(X_series)\n",
    "X_modes = np.array(X_modes)\n",
    "X_positions = np.array(X_positions)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:38:19.329889Z",
     "iopub.status.busy": "2024-05-28T13:38:19.329172Z",
     "iopub.status.idle": "2024-05-28T13:38:19.750308Z",
     "shell.execute_reply": "2024-05-28T13:38:19.749564Z",
     "shell.execute_reply.started": "2024-05-28T13:38:19.329858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " series_input (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " series_embedding (Embeddin  (None, None, 24)             672       ['series_input[0][0]']        \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, None, 32)             2336      ['series_embedding[0][0]']    \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, None, 32)             0         ['conv1d_1[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " mode_embedding (Embedding)  (None, 1, 6)                 54        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                (None, 64)                   24832     ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " lstm2 (LSTM)                (None, 64)                   22784     ['series_embedding[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TF  (None, 6)                    0         ['mode_embedding[0][0]']      \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " position_input (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, 135)                  0         ['lstm1[0][0]',               \n",
      "                                                                     'lstm2[0][0]',               \n",
      "                                                                     'tf.compat.v1.squeeze_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'position_input[0][0]']      \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 64)                   8704      ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dropout1 (Dropout)          (None, 64)                   0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm1 (BatchNormaliz  (None, 64)                   256       ['dropout1[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 64)                   4160      ['batch_norm1[0][0]']         \n",
      "                                                                                                  \n",
      " dropout2 (Dropout)          (None, 64)                   0         ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm2 (BatchNormaliz  (None, 64)                   256       ['dropout2[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dense3 (Dense)              (None, 64)                   4160      ['batch_norm2[0][0]']         \n",
      "                                                                                                  \n",
      " dropout3 (Dropout)          (None, 64)                   0         ['dense3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_norm3 (BatchNormaliz  (None, 64)                   256       ['dropout3[0][0]']            \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 28)                   1820      ['batch_norm3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70290 (274.57 KB)\n",
      "Trainable params: 69906 (273.07 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define cosine decay function for learning rate\n",
    "def cosine_decay(epoch, initial_lr):\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / epochs))\n",
    "    return initial_lr * cosine_decay\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 24\n",
    "lstm_units = 64\n",
    "mode_embedding_dim = 6\n",
    "dense_units = 64\n",
    "dropout_rate = 0.2\n",
    "initial_lr = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Input layers\n",
    "series_input = Input(shape=(None,), name='series_input')\n",
    "mode_input = Input(shape=(1,), name='mode_input')\n",
    "position_input = Input(shape=(1,), name='position_input')\n",
    "\n",
    "# Embedding layers\n",
    "series_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='series_embedding')(series_input)\n",
    "mode_embedding = Embedding(input_dim=mode_vocab_size, output_dim=mode_embedding_dim, name='mode_embedding')(mode_input)\n",
    "\n",
    "# CNN Layer\n",
    "cnn1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(series_embedding)\n",
    "pool1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "\n",
    "# LSTM layer\n",
    "lstm1 = LSTM(units=lstm_units, name='lstm1', dropout = 0, recurrent_dropout = 0)(pool1)\n",
    "lstm2 = LSTM(units=lstm_units, name='lstm2', dropout = 0, recurrent_dropout = 0)(series_embedding)\n",
    "\n",
    "# Concatenate embeddings and position input\n",
    "concatenated = Concatenate(name='concat_layer')([lstm1,lstm2 , tf.squeeze(mode_embedding, axis=1), position_input])\n",
    "\n",
    "# Dense layers with dropout and batch normalization\n",
    "dense1 = Dense(units=dense_units, activation='relu', name='dense1')(concatenated)\n",
    "dropout1 = Dropout(rate=dropout_rate, name='dropout1')(dense1)\n",
    "batch_norm1 = BatchNormalization(name='batch_norm1')(dropout1)\n",
    "\n",
    "dense2 = Dense(units=dense_units, activation='relu', name='dense2')(batch_norm1)\n",
    "dropout2 = Dropout(rate=dropout_rate, name='dropout2')(dense2)\n",
    "batch_norm2 = BatchNormalization(name='batch_norm2')(dropout2)\n",
    "\n",
    "\n",
    "dense3 = Dense(units=dense_units, activation='relu', name='dense3')(batch_norm2)\n",
    "dropout3 = Dropout(rate=dropout_rate, name='dropout3')(dense3)\n",
    "batch_norm3 = BatchNormalization(name='batch_norm3')(dropout3)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=vocab_size, activation='softmax', name='output')(batch_norm3)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=[series_input, mode_input, position_input], outputs=output, name='LSTM_Model')\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = LearningRateScheduler(schedule=lambda epoch: cosine_decay(epoch, initial_lr))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-28T13:38:23.960711Z",
     "iopub.status.busy": "2024-05-28T13:38:23.960302Z",
     "iopub.status.idle": "2024-05-28T13:54:01.669061Z",
     "shell.execute_reply": "2024-05-28T13:54:01.667931Z",
     "shell.execute_reply.started": "2024-05-28T13:38:23.960691Z"
    },
    "id": "G9_9mRMhyvYu",
    "outputId": "c4a4eca3-a0f1-4e63-b0f8-a2b2b159c279",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 10:14:14.076362: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 417706400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10527/10527 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.4350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 10:16:40.206318: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 104426600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10527/10527 [==============================] - 158s 15ms/step - loss: 1.4662 - accuracy: 0.4350 - val_loss: 1.2669 - val_accuracy: 0.5133 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.2866 - accuracy: 0.5134 - val_loss: 1.1979 - val_accuracy: 0.5475 - lr: 9.9901e-04\n",
      "Epoch 3/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.2364 - accuracy: 0.5379 - val_loss: 1.1676 - val_accuracy: 0.5579 - lr: 9.9606e-04\n",
      "Epoch 4/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.2061 - accuracy: 0.5518 - val_loss: 1.1542 - val_accuracy: 0.5629 - lr: 9.9114e-04\n",
      "Epoch 5/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.1861 - accuracy: 0.5603 - val_loss: 1.1438 - val_accuracy: 0.5676 - lr: 9.8429e-04\n",
      "Epoch 6/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.1702 - accuracy: 0.5668 - val_loss: 1.1361 - val_accuracy: 0.5715 - lr: 9.7553e-04\n",
      "Epoch 7/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.1567 - accuracy: 0.5728 - val_loss: 1.1320 - val_accuracy: 0.5722 - lr: 9.6489e-04\n",
      "Epoch 8/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.1445 - accuracy: 0.5769 - val_loss: 1.1355 - val_accuracy: 0.5697 - lr: 9.5241e-04\n",
      "Epoch 9/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.1356 - accuracy: 0.5821 - val_loss: 1.1288 - val_accuracy: 0.5739 - lr: 9.3815e-04\n",
      "Epoch 10/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.1282 - accuracy: 0.5854 - val_loss: 1.1242 - val_accuracy: 0.5750 - lr: 9.2216e-04\n",
      "Epoch 11/50\n",
      "10527/10527 [==============================] - 151s 14ms/step - loss: 1.1204 - accuracy: 0.5869 - val_loss: 1.1270 - val_accuracy: 0.5749 - lr: 9.0451e-04\n",
      "Epoch 12/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.1131 - accuracy: 0.5906 - val_loss: 1.1210 - val_accuracy: 0.5754 - lr: 8.8526e-04\n",
      "Epoch 13/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.1066 - accuracy: 0.5934 - val_loss: 1.1246 - val_accuracy: 0.5761 - lr: 8.6448e-04\n",
      "Epoch 14/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.1002 - accuracy: 0.5958 - val_loss: 1.1201 - val_accuracy: 0.5752 - lr: 8.4227e-04\n",
      "Epoch 15/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0963 - accuracy: 0.5981 - val_loss: 1.1175 - val_accuracy: 0.5788 - lr: 8.1871e-04\n",
      "Epoch 16/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0905 - accuracy: 0.6003 - val_loss: 1.1183 - val_accuracy: 0.5770 - lr: 7.9389e-04\n",
      "Epoch 17/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0865 - accuracy: 0.6029 - val_loss: 1.1212 - val_accuracy: 0.5751 - lr: 7.6791e-04\n",
      "Epoch 18/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0807 - accuracy: 0.6049 - val_loss: 1.1172 - val_accuracy: 0.5783 - lr: 7.4088e-04\n",
      "Epoch 19/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0767 - accuracy: 0.6073 - val_loss: 1.1203 - val_accuracy: 0.5780 - lr: 7.1289e-04\n",
      "Epoch 20/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0727 - accuracy: 0.6084 - val_loss: 1.1199 - val_accuracy: 0.5780 - lr: 6.8406e-04\n",
      "Epoch 21/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0680 - accuracy: 0.6107 - val_loss: 1.1211 - val_accuracy: 0.5773 - lr: 6.5451e-04\n",
      "Epoch 22/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0635 - accuracy: 0.6115 - val_loss: 1.1217 - val_accuracy: 0.5783 - lr: 6.2434e-04\n",
      "Epoch 23/50\n",
      "10527/10527 [==============================] - 150s 14ms/step - loss: 1.0598 - accuracy: 0.6141 - val_loss: 1.1196 - val_accuracy: 0.5777 - lr: 5.9369e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc5c53adc30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit([X_series, X_modes, X_positions], y,\n",
    "          validation_split=0.2, epochs=epochs, batch_size=64,\n",
    "          callbacks=[early_stopping, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p12jdV3Z59XH",
    "outputId": "f3366c60-3c50-43f4-9950-0e6a7b28f2e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(f'models/{MODEL}/melody_prediction_model_with_notes_until_end.h5')\n",
    "\n",
    "# Save the dictionaries\n",
    "with open(f'models/{MODEL}/pitch_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_dict, f)\n",
    "\n",
    "with open(f'models/{MODEL}/mode_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(mode_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
